{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the optimal number of hidden layers and neurons for an Artificial Neuron Network(ANN)\n",
    "\n",
    "This can be challending and often requires experimentation. However , Ther are some of Guidelines and methods taht can help yoi in amking an infomed decison :\n",
    "- Start Simple : Begin with a simple architecture and gradully increase complexity if needed.\n",
    "- Gris Search/ Random Search : Use grid search or random search to try sifferent achitectures.\n",
    "- Cross-Validation : Use cross- Validation to evalute the performance of different achitectures.\n",
    "- Heuristic and Rule of Thumb : Some heuristic and emperical rules can provide starting point, such as :\n",
    "    - The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "    - A common practice is to start with 1-2 hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoder = onehot_encoder.fit_transform(data[['Geography']])\n",
    "\n",
    "geo_encoder_df = pd.DataFrame(geo_encoder.toarray(), columns=onehot_encoder.get_feature_names_out(['Geography']))\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder()\n",
    "geo_encoder = onehot_encoder.fit_transform(data[['Geography']])\n",
    "geo_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_encoder_df = pd.DataFrame(geo_encoder.toarray(), columns=onehot_encoder.get_feature_names_out(['Geography']))\n",
    "geo_encoder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine One hot encoder column with the original data\n",
    "data = pd.concat([data.drop('Geography',axis=1),geo_encoder_df],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Exited',axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "## Split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "##Scale these feature\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try differnt parameters(Keras Classifier)\n",
    "\n",
    "def create_model(neurons = 32 , layers=1):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons,activation='relu'))\n",
    "        \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer = 'adam',loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Classifier\n",
    "\n",
    "model = KerasClassifier(neurons = 32 , layers=1,build_fn = create_model, verbose = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid Search Parameters\n",
    "param_grid = {\n",
    "    'neurons' : [16,32,64,128],\n",
    "    'layers':[1,2,3],\n",
    "    'epochs':[50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = model, param_grid = param_grid,n_jobs =-1,cv=3,verbose=1)\n",
    "grid_result = grid.fit(X_train,y_train)\n",
    "\n",
    "#Print The best parameters\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
